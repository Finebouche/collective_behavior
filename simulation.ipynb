{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "615b7cc4-c1da-49fb-85a5-29eee064dd0d",
   "metadata": {},
   "source": [
    "### Some preliminary checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96221f2954eecc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ray \n",
    "\n",
    "#os.environ[\"RAY_DEDUP_LOGS\"] = \"0\"\n",
    "\n",
    "print(\"Ray version :\", ray.__version__)\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"MPS Available:\", torch.backends.mps.is_available())\n",
    "\n",
    "torch._dynamo.list_backends()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6e711d-75a9-4f97-ac7f-092552034613",
   "metadata": {},
   "source": [
    "### To modify : Number of CPUs and GPUs available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9367a277-f21e-4ccb-9fc1-c5c1c1dd292b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "print(\"Number of CPUs: \", psutil.cpu_count())\n",
    "\n",
    "num_cpus = 12\n",
    "num_gpus = 0\n",
    "\n",
    "assert num_cpus <= psutil.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d421e6f2-e64c-4f7c-8ef2-cd969f9888fe",
   "metadata": {},
   "source": [
    "# Environement and algorithm configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4828732386e52c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.policy.policy import PolicySpec\n",
    "\n",
    "from ray.tune.registry import get_trainable_cls\n",
    "\n",
    "from importlib import reload\n",
    "import particle_2d_env\n",
    "reload(particle_2d_env)\n",
    "from particle_2d_env import Particle2dEnvironment\n",
    "from particle_2d_env import MetricsCallbacks, RenderingCallbacks\n",
    "from config import run_config\n",
    "\n",
    "ALGO = \"PPO\"        \n",
    "FRAMEWORK= \"torch\" # always \"torch\"\n",
    "env = Particle2dEnvironment(run_config[\"env\"])\n",
    "\n",
    "def create_callbacks():\n",
    "    return [RenderingCallbacks(), MetricsCallbacks()]\n",
    "\n",
    "config = (\n",
    "    get_trainable_cls(ALGO).get_default_config()\n",
    "    .environment(Particle2dEnvironment, env_config=run_config[\"env\"])\n",
    "    .framework(FRAMEWORK,)\n",
    "    .api_stack(enable_rl_module_and_learner=True,enable_env_runner_and_connector_v2=True,)\n",
    "#    .callbacks(RenderingCallbacks)\n",
    "    # Specify the learner's hyperparameters.\n",
    "    .training(\n",
    "        num_epochs=10,\n",
    "        train_batch_size_per_learner=512, \n",
    "    )\n",
    "    .rl_module(\n",
    "        model_config={\n",
    "            \"fcnet_hiddens\": [128, 128, 128], \n",
    "            \"use_attention\": True,\n",
    "        },\n",
    "    )\n",
    "    .multi_agent(\n",
    "        policies= {\n",
    "            \"prey\": PolicySpec(\n",
    "                policy_class=None,  # infer automatically from Algorithm\n",
    "                observation_space=env.observation_space[0],  # if None infer automatically from env\n",
    "                action_space=env.action_space[0],  # if None infer automatically from env\n",
    "                config={\"gamma\": 0.85},  # use main config plus <- this override here\n",
    "            ),\n",
    "            \"predator\": PolicySpec(\n",
    "                policy_class=None,\n",
    "                observation_space=env.observation_space[0],\n",
    "                action_space=env.action_space[0],\n",
    "                config={\"gamma\": 0.85},\n",
    "            ),\n",
    "        },\n",
    "        policy_mapping_fn = lambda id, *arg, **karg: \"prey\" if env.particule_agents[id].agent_type == 0 else \"predator\",\n",
    "        policies_to_train=[\"prey\", \"predator\"],\n",
    "        count_steps_by=\"agent_steps\",\n",
    "    )\n",
    "    .learners(\n",
    "        num_learners=4,  # or >2\n",
    "        num_cpus_per_learner=1,  # <- default 1\n",
    "        num_gpus_per_learner=0,  # <- default 0\n",
    "    )\n",
    "    .resources(num_cpus_for_main_process=1)  # <- default  1\n",
    "    .env_runners(\n",
    "        rollout_fragment_length=\"auto\", #\"auto\" for PPO explained here : https://docs.ray.io/en/latest/rllib/rllib-sample-collection.html\n",
    "        batch_mode= 'truncate_episodes',\n",
    "        num_env_runners=1, # need 2 for IMPALA, 1 for PPO\n",
    "        num_envs_per_env_runner=1,\n",
    "    )\n",
    "    .checkpointing(export_native_model_files=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd95c1-c2d5-439c-9478-cf1f15c10244",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda2dedd-1743-448e-9885-a656f210e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_folder = None # is something like \"PPO_2024-12-18_20-12-15\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5385022-05b2-42ae-a406-87b46736f257",
   "metadata": {},
   "source": [
    "## Launch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b472ec59b1f433e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import train, tune\n",
    "from ray.air.integrations.wandb import WandbLoggerCallback\n",
    "import os\n",
    "\n",
    "ray.init(\n",
    "    num_cpus=num_cpus, \n",
    "    num_gpus=num_gpus,\n",
    "    ignore_reinit_error = True,\n",
    ")\n",
    "\n",
    "# Read the API key from the file to use Wanddb\n",
    "with open('wandb_api_key.txt', 'r') as file:\n",
    "    api_key = file.read().strip()\n",
    "callbacks = [\n",
    "    WandbLoggerCallback(                   \n",
    "        project=\"marl-rllib\", \n",
    "        group=ALGO,\n",
    "        api_key=api_key,\n",
    "        log_config=True,\n",
    "        upload_checkpoints=True\n",
    "    ), \n",
    "]\n",
    "\n",
    "# Where to save \n",
    "# absolute path + ray_results directory\n",
    "storage_path=os.getcwd() + \"/ray_results\"\n",
    "\n",
    "if checkpoint_folder is None : \n",
    "    tuner = tune.Tuner(\n",
    "        trainable = ALGO,                                     # Defined before\n",
    "        param_space=config,                                   # Defined before\n",
    "        run_config=train.RunConfig(    \n",
    "            storage_path=storage_path,\n",
    "            stop={\"training_iteration\": 1500},\n",
    "            verbose=3,\n",
    "            callbacks=callbacks,\n",
    "            checkpoint_config=train.CheckpointConfig(         \n",
    "                checkpoint_at_end=True,\n",
    "                checkpoint_frequency=10,\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "# If we start a training that failed\n",
    "else: \n",
    "    path = storage_path + \"/\" + checkpoint_folder\n",
    "    # Restore the training\n",
    "    tuner = tune.Tuner.restore(\n",
    "        trainable = ALGO,\n",
    "        path = path, \n",
    "        resume_unfinished=True, \n",
    "        resume_errored=True,\n",
    "        restart_errored=False,\n",
    "    )\n",
    "    \n",
    "\n",
    "# Run the experiment \n",
    "results = tuner.fit()\n",
    "\n",
    "ray.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320d90a6-5207-4d0c-86bb-c1bef3ae8ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc5f306-eb46-410a-80a3-6050faaa92ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collective_behavior",
   "language": "python",
   "name": "collective_behavior"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
