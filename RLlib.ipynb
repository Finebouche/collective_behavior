{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b6dda5f-a9b9-4d09-8891-5672135f526a",
   "metadata": {},
   "source": [
    "# Our Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "024e0e5c-cee0-4040-9380-b39c9163e345",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T13:02:51.830508Z",
     "iopub.status.busy": "2023-09-07T13:02:51.829725Z",
     "iopub.status.idle": "2023-09-07T13:02:59.143323Z",
     "shell.execute_reply": "2023-09-07T13:02:59.141859Z",
     "shell.execute_reply.started": "2023-09-07T13:02:51.830473Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 13:02:54.587348: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-07 13:02:56.051974: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.0.1+cu117\n",
      "CUDA Available: True\n",
      "CUDA Version: 11.7\n",
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82dfc156-a283-4a91-a2e5-6e97568ea596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-07T13:49:00.120788Z",
     "iopub.status.busy": "2023-09-07T13:49:00.120118Z",
     "iopub.status.idle": "2023-09-07T14:22:45.917961Z",
     "shell.execute_reply": "2023-09-07T14:22:45.916243Z",
     "shell.execute_reply.started": "2023-09-07T13:49:00.120710Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 13:49:03,306\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "2023-09-07 13:49:13,063\tWARNING algorithm_config.py:2558 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2023-09-07 13:49:13,078\tWARNING algorithm_config.py:2558 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2023-09-07 13:49:13,087\tWARNING algorithm_config.py:2558 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "2023-09-07 13:49:13,097\tINFO tune.py:657 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-09-07 14:22:42</td></tr>\n",
       "<tr><td>Running for: </td><td>00:33:29.38        </td></tr>\n",
       "<tr><td>Memory:      </td><td>503.0/1510.5 GiB   </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 5.0/96 CPUs, 4.0/4 GPUs (0.0/1.0 accelerator_type:V100)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CustomEnvironment_540a9_00000</td><td style=\"text-align: right;\">           1</td><td>/home/tcazalet/ray_results/PPO/PPO_CustomEnvironment_540a9_00000_0_2023-09-07_13-49-13/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th>status  </th><th>loc              </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CustomEnvironment_540a9_00000</td><td>ERROR   </td><td>172.17.0.14:39835</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         109.675</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">-180.471</td><td style=\"text-align: right;\">            -168.186</td><td style=\"text-align: right;\">            -205.908</td><td style=\"text-align: right;\">              1000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 13:49:13,116\tWARNING algorithm_config.py:2558 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "\u001b[2m\u001b[36m(pid=39835)\u001b[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=39835)\u001b[0m 2023-09-07 13:49:22,641\tWARNING algorithm_config.py:2558 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "\u001b[2m\u001b[36m(PPO pid=39835)\u001b[0m 2023-09-07 13:49:22,642\tWARNING algorithm_config.py:656 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(pid=40043)\u001b[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=40043)\u001b[0m 2023-09-07 13:49:31,357\tWARNING algorithm_config.py:2558 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=40043)\u001b[0m 2023-09-07 13:49:31,374\tWARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=40043)\u001b[0m 2023-09-07 13:49:31,374\tWARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=40043)\u001b[0m 2023-09-07 13:49:31,374\tWARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=40043)\u001b[0m 2023-09-07 13:49:31,374\tWARNING deprecation.py:50 -- DeprecationWarning: `KLCoeffMixin` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=40043)\u001b[0m 2023-09-07 13:49:31,388\tWARNING algorithm_config.py:2558 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\n",
      "\u001b[2m\u001b[36m(pid=40168)\u001b[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=39835)\u001b[0m 2023-09-07 13:49:31,457\tWARNING algorithm_config.py:2558 -- Setting `exploration_config={}` because you set `_enable_rl_module_api=True`. When RLModule API are enabled, exploration_config can not be set. If you want to implement custom exploration behaviour, please modify the `forward_exploration` method of the RLModule at hand. On configs that have a default exploration config, this must be done with `config.exploration_config={}`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(PPO pid=39835)\u001b[0m 2023-09-07 13:49:31,444\tWARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=39835)\u001b[0m 2023-09-07 13:49:31,444\tWARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=39835)\u001b[0m 2023-09-07 13:49:31,444\tWARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=39835)\u001b[0m 2023-09-07 13:49:31,444\tWARNING deprecation.py:50 -- DeprecationWarning: `KLCoeffMixin` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=39835)\u001b[0m Starting distributed worker processes: ['40168 (172.17.0.14)', '40169 (172.17.0.14)', '40170 (172.17.0.14)', '40171 (172.17.0.14)']\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m Setting up process group for: env:// [rank=0, world_size=4]\n",
      "\u001b[2m\u001b[36m(PPO pid=39835)\u001b[0m Trainable.setup took 27.535 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=39835)\u001b[0m Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=40169)\u001b[0m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=40043)\u001b[0m 2023-09-07 13:50:37,674\tWARNING env_runner_v2.py:155 -- More than 44024 observations in 4000 env steps for episode 643392179374660364 are buffered in the sampler. If this is more than you expected, check that that you set a horizon on your environment correctly and that it terminates at some point. Note: In multi-agent environments, `rollout_fragment_length` sets the batch size based on (across-agents) environment steps, not the steps of individual agents, which can result in unexpectedly large batches.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                       </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>connector_metrics                                                                                                                                            </th><th>counters                                                                                                                   </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th style=\"text-align: right;\">  experiment_tag</th><th>hostname    </th><th>info                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip    </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_sampled_throughput_per_sec</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained_throughput_per_sec</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                           </th><th style=\"text-align: right;\">  pid</th><th>policy_reward_max                                           </th><th>policy_reward_mean                                           </th><th>policy_reward_min                                             </th><th>sampler_perf                                                                                                                                                                                                  </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                                                                 </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_CustomEnvironment_540a9_00000</td><td style=\"text-align: right;\">                  80056</td><td>{&#x27;ObsPreprocessorConnector_ms&#x27;: 0.01589655876159668, &#x27;StateBufferConnector_ms&#x27;: 0.011245906352996826, &#x27;ViewRequirementAgentConnector_ms&#x27;: 1.3507261872291565}</td><td>{&#x27;num_env_steps_sampled&#x27;: 8000, &#x27;num_env_steps_trained&#x27;: 0, &#x27;num_agent_steps_sampled&#x27;: 80056, &#x27;num_agent_steps_trained&#x27;: 0}</td><td>{}              </td><td>2023-09-07_13-51-39</td><td>False </td><td style=\"text-align: right;\">              1000</td><td>{}             </td><td style=\"text-align: right;\">            -168.186</td><td style=\"text-align: right;\">             -180.471</td><td style=\"text-align: right;\">            -205.908</td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">               8</td><td style=\"text-align: right;\">               0</td><td>fe2e97c884b6</td><td>{&#x27;learner&#x27;: {&#x27;__all__&#x27;: {&#x27;num_agent_steps_trained&#x27;: 512.0, &#x27;num_env_steps_trained&#x27;: 7008.0, &#x27;total_loss&#x27;: 0.011249048166303302}, &#x27;prey&#x27;: {&#x27;total_loss&#x27;: 0.011249048166303302, &#x27;policy_loss&#x27;: -0.004245043145475677, &#x27;vf_loss&#x27;: 0.011553500236900983, &#x27;vf_loss_unclipped&#x27;: 0.13543880806501496, &#x27;vf_explained_var&#x27;: -0.030111400152209904, &#x27;entropy&#x27;: 2.864132779140542, &#x27;mean_kl_loss&#x27;: 0.005250766952114171, &#x27;curr_lr&#x27;: 5e-05, &#x27;curr_entropy_coeff&#x27;: 0.0, &#x27;curr_kl_coeff&#x27;: 0.10000000149011612}, &#x27;predator&#x27;: {&#x27;total_loss&#x27;: 0.0034155141580068105, &#x27;policy_loss&#x27;: -0.007571948348904831, &#x27;vf_loss&#x27;: 0.009203437678134321, &#x27;vf_loss_unclipped&#x27;: 0.016845857860261257, &#x27;vf_explained_var&#x27;: -0.035182035480537555, &#x27;entropy&#x27;: 2.6974907965555674, &#x27;mean_kl_loss&#x27;: 0.008920122762169979, &#x27;curr_lr&#x27;: 5e-05, &#x27;curr_entropy_coeff&#x27;: 0.0, &#x27;curr_kl_coeff&#x27;: 0.20000000298023224}}, &#x27;num_env_steps_sampled&#x27;: 8000, &#x27;num_env_steps_trained&#x27;: 0, &#x27;num_agent_steps_sampled&#x27;: 80056, &#x27;num_agent_steps_trained&#x27;: 0}</td><td style=\"text-align: right;\">                         2</td><td>172.17.0.14</td><td style=\"text-align: right;\">                    80056</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">                   8000</td><td style=\"text-align: right;\">                             4000</td><td style=\"text-align: right;\">                                   79.3613</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                                0</td><td style=\"text-align: right;\">                                         0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                            0</td><td>{&#x27;cpu_util_percent&#x27;: 27.529166666666665, &#x27;ram_util_percent&#x27;: 32.65833333333333}</td><td style=\"text-align: right;\">39835</td><td>{&#x27;prey&#x27;: -10.000017745590373, &#x27;predator&#x27;: -5.30930330666487}</td><td>{&#x27;prey&#x27;: -11.004339080255129, &#x27;predator&#x27;: -7.702771963824885}</td><td>{&#x27;prey&#x27;: -20.018213682750982, &#x27;predator&#x27;: -10.286724535030958}</td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 5.0570805068171785, &#x27;mean_inference_ms&#x27;: 4.263618604174226, &#x27;mean_action_processing_ms&#x27;: 1.4091045959798016, &#x27;mean_env_wait_ms&#x27;: 0.7565173665295403, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: -168.18557419865178, &#x27;episode_reward_min&#x27;: -205.9078273878741, &#x27;episode_reward_mean&#x27;: -180.470630131473, &#x27;episode_len_mean&#x27;: 1000.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 4, &#x27;policy_reward_min&#x27;: {&#x27;prey&#x27;: -20.018213682750982, &#x27;predator&#x27;: -10.286724535030958}, &#x27;policy_reward_max&#x27;: {&#x27;prey&#x27;: -10.000017745590373, &#x27;predator&#x27;: -5.30930330666487}, &#x27;policy_reward_mean&#x27;: {&#x27;prey&#x27;: -11.004339080255129, &#x27;predator&#x27;: -7.702771963824885}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-176.73007458832748, -168.18557419865178, -205.9078273878741, -186.21461408245963, -171.00724767910626, -191.29643696037257, -173.60985362675117, -170.81341252824083], &#x27;episode_lengths&#x27;: [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000], &#x27;policy_prey_reward&#x27;: [-11.297270217849853, -10.018920058141273, -11.10468878310532, -10.007679710663314, -10.012103181017379, -11.132937203002562, -10.007063167804144, -10.99930513517291, -11.351434971007919, -10.011995595491562, -10.015792867790598, -10.020000000427286, -11.169568456729872, -11.50484213342416, -11.505469133888944, -10.011237864715516, -10.014010721946876, -10.012540756905995, -10.012497203066388, -11.375207322160653, -10.017897800485413, -10.011329213100295, -10.020000000427286, -10.011534212607815, -10.000017745590373, -10.006680043294052, -11.332454569286346, -11.463738998561645, -11.523662309511938, -10.006622524857397, -11.301981095974842, -11.2683206837666, -11.15885070691624, -20.00579366091105, -11.632797713668792, -11.271445796813785, -11.316454933203529, -20.016589091475492, -11.251291016538472, -11.198121146362672, -11.371809734871519, -11.191689498298555, -11.29045065444914, -11.361531870913629, -11.518455581999872, -11.446901541252332, -11.54629840645269, -11.591913625307459, -11.65803583943265, -11.480862942319105, -10.00413056525053, -10.004209727141054, -11.335690259473528, -10.002827149624522, -11.505497364544741, -11.653769531172024, -11.720885439533394, -10.01216636211859, -11.630227324452413, -11.688230335300219, -11.06189769514878, -11.18352672356134, -10.004616895007635, -10.012158798929487, -10.003207694373039, -10.007088654152945, -10.018897043297809, -11.662483088767413, -11.024152996824217, -11.29545205322791, -10.004418522988342, -10.020000000427286, -10.01657309470586, -10.017260982970518, -11.334549484669969, -20.013038581317495, -11.01637543175806, -10.994415756466285, -10.010000000278275, -10.010000000278275, -10.843449949399577, -11.052714956974562, -20.018213682750982, -10.94392069778632, -11.13444682544208, -10.761377623142007, -10.010000000278275, -10.010000000278275, -10.008636200214172, -10.871571558783131, -10.835415197671121, -10.015824305022877, -10.020000000427286, -11.079721698715517, -11.221416986896708, -10.006366684021533, -11.08519472882599, -10.004770558232751, -10.999211240560097, -10.015569143126529, -10.004757505656306, -10.01264050606879, -10.9452540532619, -10.723349778704996, -10.774579599482811, -10.015207047144692, -10.020000000427286, -11.262262699049552, -10.010000000278275, -10.010000000278275, -10.013417937363307, -10.020000000427286, -11.26284038831843, -11.204471379281118, -10.017316999415677, -11.084442210593595, -10.007663872936948, -11.02605253398473, -11.033559845320656, -10.009206233345518], &#x27;policy_predator_reward&#x27;: [-7.91576464166239, -8.655239331150312, -5.590650953824275, -6.775491958313885, -9.551985843986717, -9.200258357729737, -8.646243134058139, -10.286724535030958, -6.1710423149318645, -7.169921635124246, -5.30930330666487, -8.288972388564266, -7.436949666976132, -8.428831973102302, -8.253002536229111, -5.5639688438489365]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 5.0570805068171785, &#x27;mean_inference_ms&#x27;: 4.263618604174226, &#x27;mean_action_processing_ms&#x27;: 1.4091045959798016, &#x27;mean_env_wait_ms&#x27;: 0.7565173665295403, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0, &#x27;connector_metrics&#x27;: {&#x27;ObsPreprocessorConnector_ms&#x27;: 0.01589655876159668, &#x27;StateBufferConnector_ms&#x27;: 0.011245906352996826, &#x27;ViewRequirementAgentConnector_ms&#x27;: 1.3507261872291565}}</td><td style=\"text-align: right;\">             109.675</td><td style=\"text-align: right;\">           50.4062</td><td style=\"text-align: right;\">       109.675</td><td>{&#x27;training_iteration_time_ms&#x27;: 54833.144, &#x27;sample_time_ms&#x27;: 45111.077, &#x27;synch_weights_time_ms&#x27;: 14.388}</td><td style=\"text-align: right;\"> 1694094699</td><td style=\"text-align: right;\">             8000</td><td style=\"text-align: right;\">                   2</td><td>540a9_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m [E ProcessGroupNCCL.cpp:828] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=1869, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1800475 milliseconds before timing out.\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m [E ProcessGroupNCCL.cpp:455] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m [E ProcessGroupNCCL.cpp:460] To avoid data inconsistency, we are taking the entire process down.\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m [2023-09-07 14:22:34,820 E 40168 40567] logging.cc:97: Unhandled exception: St13runtime_error. what(): [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=1869, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1800475 milliseconds before timing out.\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m [2023-09-07 14:22:34,912 E 40168 40567] logging.cc:104: Stack trace: \n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m  /project_ghent/MARL2/collective_env/lib/python3.11/site-packages/ray/_raylet.so(+0xe48dba) [0x7fc934b87dba] ray::operator<<()\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m /project_ghent/MARL2/collective_env/lib/python3.11/site-packages/ray/_raylet.so(+0xe4b578) [0x7fc934b8a578] ray::TerminateHandler()\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m /project_ghent/MARL2/collective_env/bin/../lib/libstdc++.so.6(+0xb640c) [0x7fc933c1240c] __cxxabiv1::__terminate()\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m /project_ghent/MARL2/collective_env/bin/../lib/libstdc++.so.6(+0xb645e) [0x7fc933c1245e] __cxxabiv1::__unexpected()\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m /project_ghent/MARL2/collective_env/bin/../lib/libstdc++.so.6(+0xb6405) [0x7fc933c12405] __cxxabiv1::__terminate()\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m /project_ghent/MARL2/collective_env/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so(_ZN4c10d16ProcessGroupNCCL8WorkNCCL15handleNCCLGuardENS_17ErrorHandlingModeE+0x278) [0x7fc5eea574d8] c10d::ProcessGroupNCCL::WorkNCCL::handleNCCLGuard()\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m /project_ghent/MARL2/collective_env/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so(_ZN4c10d16ProcessGroupNCCL15workCleanupLoopEv+0x19f) [0x7fc5eea5b02f] c10d::ProcessGroupNCCL::workCleanupLoop()\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m /project_ghent/MARL2/collective_env/bin/../lib/libstdc++.so.6(+0xd3e79) [0x7fc933c2fe79] execute_native_thread_routine\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m /usr/lib/x86_64-linux-gnu/libc.so.6(+0x94b43) [0x7fc935b05b43]\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m /usr/lib/x86_64-linux-gnu/libc.so.6(clone+0x44) [0x7fc935b96bb4] __clone\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m *** SIGABRT received at time=1694096554 on cpu 37 ***\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m PC: @     0x7fc935b07a7c  (unknown)  pthread_kill\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m     @     0x7fc935ab3520  (unknown)  (unknown)\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m [2023-09-07 14:22:34,912 E 40168 40567] logging.cc:361: *** SIGABRT received at time=1694096554 on cpu 37 ***\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m [2023-09-07 14:22:34,912 E 40168 40567] logging.cc:361: PC: @     0x7fc935b07a7c  (unknown)  pthread_kill\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m [2023-09-07 14:22:34,913 E 40168 40567] logging.cc:361:     @     0x7fc935ab3520  (unknown)  (unknown)\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m Fatal Python error: Aborted\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m \n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40168)\u001b[0m Extension modules: msgpack._cmsgpack, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, setproctitle, yaml._yaml, ray._raylet, charset_normalizer.md, numpy.core._multiarray_umath, numpy.core._multiarray_tests, numpy.linalg._umath_linalg, numpy.fft._pocketfft_internal, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, tensorflow.python.framework.fast_tensor_util, h5py._errors, h5py.defs, h5py._objects, h5py.h5, h5py.h5r, h5py.utils, h5py.h5s, h5py.h5ac, h5py.h5p, h5py.h5t, h5py._conv, h5py.h5z, h5py._proxy, h5py.h5a, h5py.h5d, h5py.h5ds, h5py.h5g, h5py.h5i, h5py.h5f, h5py.h5fd, h5py.h5pl, h5py.h5o, h5py.h5l, h5py._selector, scipy._lib._ccallback_c, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.sparse.linalg._isolve._iterative, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg.cython_lapack, scipy.linalg._cythonized_array_utils, scipy.linalg._solve_toeplitz, scipy.linalg._decomp_lu_cython, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg.cython_blas, scipy.linalg._matfuncs_expm, scipy.linalg._decomp_update, scipy.linalg._flinalg, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, lz4._version, lz4.frame._frame, PIL._imaging, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pandas._libs.hashing, pyarrow.lib, pyarrow._hdfsio, pandas._libs.tslib, pandas._libs.ops, pyarrow._compute, pandas._libs.arrays, pandas._libs.sparse, pandas._libs.reduction, pandas._libs.indexing, pandas._libs.index, pandas._libs.internals, pandas._libs.join, pandas._libs.writers, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.testing, pandas._libs.parsers, pandas._libs.json, scipy.ndimage._nd_image, scipy.special._ufuncs_cxx, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy.special._ellip_harm_2, _ni_label, scipy.ndimage._ni_label, torch._C, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, pyarrow._fs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, grpc._cython.cygrpc, skimage._shared.geometry, scipy.spatial._ckdtree, scipy._lib.messagestream, scipy.spatial._qhull, scipy.spatial._voronoi, scipy.spatial._distance_wrap, scipy.spatial._hausdorff, scipy.spatial.transform._rotation, skimage.draw._draw, skimage.transform._hough_transform, scipy.interpolate._fitpack, scipy.interpolate.dfitpack, scipy.optimize._minpack2, scipy.optimize._group_columns, scipy.optimize._trlib._trlib, numpy.linalg.lapack_lite, scipy.optimize._lbfgsb, _moduleTNC, scipy.optimize._moduleTNC, scipy.optimize._cobyla, scipy.optimize._slsqp, scipy.optimize._minpack, scipy.optimize._lsq.givens_elimination, scipy.optimize._zeros, scipy.optimize.__nnls, scipy.optimize._highs.cython.src._highs_wrapper, scipy.optimize._highs._highs_wrapper, scipy.optimize._highs.cython.src._highs_constants, scipy.optimize._highs._highs_constants, scipy.linalg._interpolative, scipy.optimize._bglu_dense, scipy.optimize._lsap, scipy.optimize._direct, scipy.interpolate._bspl, scipy.interpolate._ppoly, scipy.interpolate.interpnd, scipy.interpolate._rbfinterp_pythran, scipy.interpolate._rgi_cython, scipy._lib._uarray._uarray, skimage.transform._warps_cy, skimage.measure._find_contours_cy, skimage.measure._marching_cubes_lewiner_cy, skimage.measure._moments_cy, scipy.signal._sigtools, scipy.signal._max_len_seq_inner, scipy.signal._upfirdn_apply, scipy.signal._spline, scipy.integrate._odepack, scipy.integrate._quadpack, scipy.integrate._vode, scipy.integrate._dop, scipy.integrate._lsoda, scipy.signal._sosfilt, scipy.signal._spectral, scipy.special.cython_special, scipy.stats._stats, scipy.stats.beta_ufunc, scipy.stats._boost.beta_ufunc, scipy.stats.binom_ufunc, scipy.stats._boost.binom_ufunc, scipy.stats.nbinom_ufunc, scipy.stats._boost.nbinom_ufunc, scipy.stats.hypergeom_ufunc, scipy.stats._boost.hypergeom_ufunc, scipy.stats.ncf_ufunc, scipy.stats._boost.ncf_ufunc, scipy.stats.ncx2_ufunc, scipy.stats._boost.ncx2_ufunc, scipy.stats.nct_ufunc, scipy.stats._boost.nct_ufunc, scipy.stats.skewnorm_ufunc, scipy.stats._boost.skewnorm_ufunc, scipy.stats.invgauss_ufunc, scipy.stats._boost.invgauss_ufunc, scipy.stats._biasedurn, scipy.stats._levy_stable.levyst, scipy.stats._stats_pythran, scipy.stats._statlib, scipy.stats._sobol, scipy.stats._qmc_cy, scipy.stats._mvn, scipy.stats._rcont.rcont, scipy.signal._peak_finding_utils, skimage.measure._pnpoly, skimage.measure._ccomp, skimage.transform._radon_transform, pyarrow._json (total: 225)\n",
      "2023-09-07 14:22:35,802\tWARNING worker.py:2033 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff2d36c5fed7a3e2bc9d24ac5f01000000 Worker ID: 3b43b555413f7740c269b36523a905e7514a0c657edf5c10b266d46f Node ID: 62011b36a661a4490dcc71b9a4b70927276cef1c1142413b018cecb5 Worker IP address: 172.17.0.14 Worker port: 42315 Worker PID: 40168 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "2023-09-07 14:22:35,976\tWARNING worker.py:2033 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff37b4e66ababf566b9b7311c901000000 Worker ID: e95937c9153da9203faea7dc1ac5c85c01e912194e655c93ac8fec30 Node ID: 62011b36a661a4490dcc71b9a4b70927276cef1c1142413b018cecb5 Worker IP address: 172.17.0.14 Worker port: 41107 Worker PID: 40169 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40170)\u001b[0m [E ProcessGroupNCCL.cpp:828] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=1869, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1809501 milliseconds before timing out.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40169)\u001b[0m [E ProcessGroupNCCL.cpp:455] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40169)\u001b[0m [E ProcessGroupNCCL.cpp:460] To avoid data inconsistency, we are taking the entire process down.\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40169)\u001b[0m [2023-09-07 14:22:34,844 E 40169 40565] logging.cc:97: Unhandled exception: St13runtime_error. what(): [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=1869, OpType=ALLREDUCE, Timeout(ms)=1800000) ran for 1800459 milliseconds before timing out.\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40169)\u001b[0m [2023-09-07 14:22:34,907 E 40169 40565] logging.cc:104: Stack trace: \n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40169)\u001b[0m  /project_ghent/MARL2/collective_env/lib/python3.11/site-packages/ray/_raylet.so(+0xe48dba) [0x7fc62f849dba] ray::operator<<()\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40169)\u001b[0m /project_ghent/MARL2/collective_env/lib/python3.11/site-packages/ray/_raylet.so(+0xe4b578) [0x7fc62f84c578] ray::TerminateHandler()\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40169)\u001b[0m \u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40169)\u001b[0m /project_ghent/MARL2/collective_env/bin/../lib/libstdc++.so.6(+0xd3e79) [0x7fc62e8f1e79] execute_native_thread_routine\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40169)\u001b[0m /usr/lib/x86_64-linux-gnu/libc.so.6(clone+0x44) [0x7fc630858bb4] __clone\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40169)\u001b[0m *** SIGABRT received at time=1694096554 on cpu 76 ***\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40169)\u001b[0m PC: @     0x7fc6307c9a7c  (unknown)  pthread_kill\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40169)\u001b[0m     @     0x7fc630775520  (unknown)  (unknown)\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40169)\u001b[0m [2023-09-07 14:22:34,908 E 40169 40565] logging.cc:361: *** SIGABRT received at time=1694096554 on cpu 76 ***\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40169)\u001b[0m [2023-09-07 14:22:34,908 E 40169 40565] logging.cc:361: PC: @     0x7fc6307c9a7c  (unknown)  pthread_kill\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40169)\u001b[0m [2023-09-07 14:22:34,908 E 40169 40565] logging.cc:361:     @     0x7fc630775520  (unknown)  (unknown)\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40169)\u001b[0m Fatal Python error: Aborted\n",
      "\u001b[2m\u001b[36m(_WrappedExecutable pid=40169)\u001b[0m Extension modules: msgpack._cmsgpack, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, setproctitle, yaml._yaml, ray._raylet, charset_normalizer.md, numpy.core._multiarray_umath, numpy.core._multiarray_tests, numpy.linalg._umath_linalg, numpy.fft._pocketfft_internal, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, tensorflow.python.framework.fast_tensor_util, h5py._errors, h5py.defs, h5py._objects, h5py.h5, h5py.h5r, h5py.utils, h5py.h5s, h5py.h5ac, h5py.h5p, h5py.h5t, h5py._conv, h5py.h5z, h5py._proxy, h5py.h5a, h5py.h5d, h5py.h5ds, h5py.h5g, h5py.h5i, h5py.h5f, h5py.h5fd, h5py.h5pl, h5py.h5o, h5py.h5l, h5py._selector, scipy._lib._ccallback_c, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.sparse.linalg._isolve._iterative, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg.cython_lapack, scipy.linalg._cythonized_array_utils, scipy.linalg._solve_toeplitz, scipy.linalg._decomp_lu_cython, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg.cython_blas, scipy.linalg._matfuncs_expm, scipy.linalg._decomp_update, scipy.linalg._flinalg, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, lz4._version, lz4.frame._frame, PIL._imaging, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pandas._libs.hashing, pyarrow.lib, pyarrow._hdfsio, pandas._libs.tslib, pandas._libs.ops, pyarrow._compute, pandas._libs.arrays, pandas._libs.sparse, pandas._libs.reduction, pandas._libs.indexing, pandas._libs.index, pandas._libs.internals, pandas._libs.join, pandas._libs.writers, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.testing, pandas._libs.parsers, pandas._libs.json, scipy.ndimage._nd_image, scipy.special._ufuncs_cxx, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy.special._ellip_harm_2, _ni_label, scipy.ndimage._ni_label, torch._C, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, pyarrow._fs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, grpc._cython.cygrpc, skimage._shared.geometry, scipy.spatial._ckdtree, scipy._lib.messagestream, scipy.spatial._qhull, scipy.spatial._voronoi, scipy.spatial._distance_wrap, scipy.spatial._hausdorff, scipy.spatial.transform._rotation, skimage.draw._draw, skimage.transform._hough_transform, scipy.interpolate._fitpack, scipy.interpolate.dfitpack, scipy.optimize._minpack2, scipy.optimize._group_columns, scipy.optimize._trlib._trlib, numpy.linalg.lapack_lite, scipy.optimize._lbfgsb, _moduleTNC, scipy.optimize._moduleTNC, scipy.optimize._cobyla, scipy.optimize._slsqp, scipy.optimize._minpack, scipy.optimize._lsq.givens_elimination, scipy.optimize._zeros, scipy.optimize.__nnls, scipy.optimize._highs.cython.src._highs_wrapper, scipy.optimize._highs._highs_wrapper, scipy.optimize._highs.cython.src._highs_constants, scipy.optimize._highs._highs_constants, scipy.linalg._interpolative, scipy.optimize._bglu_dense, scipy.optimize._lsap, scipy.optimize._direct, scipy.interpolate._bspl, scipy.interpolate._ppoly, scipy.interpolate.interpnd, scipy.interpolate._rbfinterp_pythran, scipy.interpolate._rgi_cython, scipy._lib._uarray._uarray, skimage.transform._warps_cy, skimage.measure._find_contours_cy, skimage.measure._marching_cubes_lewiner_cy, skimage.measure._moments_cy, scipy.signal._sigtools, scipy.signal._max_len_seq_inner, scipy.signal._upfirdn_apply, scipy.signal._spline, scipy.integrate._odepack, scipy.integrate._quadpack, scipy.integrate._vode, scipy.integrate._dop, scipy.integrate._lsoda, scipy.signal._sosfilt, scipy.signal._spectral, scipy.special.cython_special, scipy.stats._stats, scipy.stats.beta_ufunc, scipy.stats._boost.beta_ufunc, scipy.stats.binom_ufunc, scipy.stats._boost.binom_ufunc, scipy.stats.nbinom_ufunc, scipy.stats._boost.nbinom_ufunc, scipy.stats.hypergeom_ufunc, scipy.stats._boost.hypergeom_ufunc, scipy.stats.ncf_ufunc, scipy.stats._boost.ncf_ufunc, scipy.stats.ncx2_ufunc, scipy.stats._boost.ncx2_ufunc, scipy.stats.nct_ufunc, scipy.stats._boost.nct_ufunc, scipy.stats.skewnorm_ufunc, scipy.stats._boost.skewnorm_ufunc, scipy.stats.invgauss_ufunc, scipy.stats._boost.invgauss_ufunc, scipy.stats._biasedurn, scipy.stats._levy_stable.levyst, scipy.stats._stats_pythran, scipy.stats._statlib, scipy.stats._sobol, scipy.stats._qmc_cy, scipy.stats._mvn, scipy.stats._rcont.rcont, scipy.signal._peak_finding_utils, skimage.measure._pnpoly, skimage.measure._ccomp, skimage.transform._radon_transform, pyarrow._json (total: 225)\n",
      "\u001b[2m\u001b[36m(PPO pid=39835)\u001b[0m 2023-09-07 14:22:42,247\tERROR actor_manager.py:500 -- Ray error, taking actor 0 out of service. The actor died unexpectedly before finishing this task.\n",
      "\u001b[2m\u001b[36m(PPO pid=39835)\u001b[0m \tclass_name: create_executable_class.<locals>._WrappedExecutable\n",
      "\u001b[2m\u001b[36m(PPO pid=39835)\u001b[0m \tactor_id: 2d36c5fed7a3e2bc9d24ac5f01000000\n",
      "\u001b[2m\u001b[36m(PPO pid=39835)\u001b[0m \tpid: 40168\n",
      "\u001b[2m\u001b[36m(PPO pid=39835)\u001b[0m \tnamespace: 3858691c-4ceb-403c-8c2e-fe31380b86d1\n",
      "\u001b[2m\u001b[36m(PPO pid=39835)\u001b[0m \tip: 172.17.0.14\n",
      "\u001b[2m\u001b[36m(PPO pid=39835)\u001b[0m The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "2023-09-07 14:22:42,435\tERROR tune_controller.py:911 -- Trial task failed for trial PPO_CustomEnvironment_540a9_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/project_ghent/MARL2/collective_env/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/project_ghent/MARL2/collective_env/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/project_ghent/MARL2/collective_env/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/project_ghent/MARL2/collective_env/lib/python3.11/site-packages/ray/_private/worker.py\", line 2520, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::PPO.train()\u001b[39m (pid=39835, ip=172.17.0.14, actor_id=5130342180432ed0347c747401000000, repr=PPO)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/project_ghent/MARL2/collective_env/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 375, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/project_ghent/MARL2/collective_env/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 372, in train\n",
      "    result = self.step()\n",
      "             ^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/project_ghent/MARL2/collective_env/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py\", line 853, in step\n",
      "    results, train_iter_ctx = self._run_one_training_iteration()\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/project_ghent/MARL2/collective_env/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py\", line 2837, in _run_one_training_iteration\n",
      "    results = self.training_step()\n",
      "              ^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/project_ghent/MARL2/collective_env/lib/python3.11/site-packages/ray/rllib/algorithms/ppo/ppo.py\", line 488, in training_step\n",
      "    self.workers.sync_weights(\n",
      "  File \"/project_ghent/MARL2/collective_env/lib/python3.11/site-packages/ray/rllib/evaluation/worker_set.py\", line 386, in sync_weights\n",
      "    weights = weights_src.get_weights(policies)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/project_ghent/MARL2/collective_env/lib/python3.11/site-packages/ray/rllib/core/learner/learner_group.py\", line 466, in get_weights\n",
      "    state = self._get_results(state)[0]\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/project_ghent/MARL2/collective_env/lib/python3.11/site-packages/ray/rllib/core/learner/learner_group.py\", line 344, in _get_results\n",
      "    raise result_or_error\n",
      "  File \"/project_ghent/MARL2/collective_env/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py\", line 481, in __fetch_result\n",
      "    result = ray.get(r)\n",
      "             ^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: create_executable_class.<locals>._WrappedExecutable\n",
      "\tactor_id: 2d36c5fed7a3e2bc9d24ac5f01000000\n",
      "\tpid: 40168\n",
      "\tnamespace: 3858691c-4ceb-403c-8c2e-fe31380b86d1\n",
      "\tip: 172.17.0.14\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "2023-09-07 14:22:42,846\tERROR tune.py:1144 -- Trials did not complete: [PPO_CustomEnvironment_540a9_00000]\n",
      "2023-09-07 14:22:42,848\tINFO tune.py:1148 -- Total run time: 2009.75 seconds (2009.34 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray import air, tune\n",
    "from ray.rllib.utils.test_utils import check_learning_achieved\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "from custom_env import CustomEnvironment\n",
    "from config import run_config\n",
    "\n",
    "## The RLlib configuration\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.run = \"PPO\"\n",
    "        self.framework = \"torch\" # \"tf2\" or \"torch\"\n",
    "        self.stop_iters = 5\n",
    "        self.stop_timesteps = 100000\n",
    "        self.stop_reward = 0.1\n",
    "        self.as_test = False\n",
    "\n",
    "args = Args()\n",
    "\n",
    "## Generate the configuration\n",
    "ray.init()\n",
    "env = CustomEnvironment(run_config[\"env\"])\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .rollouts(rollout_fragment_length=\"auto\", num_rollout_workers=1)\n",
    "    .environment(CustomEnvironment, env_config=run_config[\"env\"])\n",
    "    .framework(args.framework)\n",
    "    .training(num_sgd_iter=10, sgd_minibatch_size=256, train_batch_size=4000)\n",
    "    .multi_agent(\n",
    "        policies= {\n",
    "            \"prey\": PolicySpec(\n",
    "                policy_class=None,  # infer automatically from Algorithm\n",
    "                observation_space=env.observation_space[0],  # if None infer automatically from env\n",
    "                action_space=env.action_space[0],  # if None infer automatically from env\n",
    "                config={\"gamma\": 0.85},  # use main config plus <- this override here\n",
    "            ),\n",
    "            \"predator\": PolicySpec(\n",
    "                policy_class=None,\n",
    "                observation_space=env.observation_space[0],\n",
    "                action_space=env.action_space[0],\n",
    "                config={\"gamma\": 0.85},\n",
    "            ),\n",
    "        },\n",
    "        policy_mapping_fn = lambda id, *arg, **karg: \"prey\" if env.agents[id].agent_type == 0 else \"predator\",\n",
    "        policies_to_train=[\"prey\", \"predator\"]\n",
    "    )\n",
    "    .rl_module(_enable_rl_module_api=True)\n",
    "    .training(_enable_learner_api=True)\n",
    "    .resources(\n",
    "        num_gpus_per_learner_worker=1,\n",
    "        num_cpus_per_worker = 4,\n",
    "        num_learner_workers= 4\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "stop = {\n",
    "    \"training_iteration\": args.stop_iters,\n",
    "    \"timesteps_total\": args.stop_timesteps,\n",
    "    \"episode_reward_mean\": args.stop_reward,\n",
    "}\n",
    "\n",
    "## Run the experiemnt    \n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    args.run,\n",
    "    param_space=config.to_dict(),\n",
    "    run_config=air.RunConfig(stop=stop, verbose=3),\n",
    ")\n",
    "results = tuner.fit()\n",
    "\n",
    "if args.as_test:\n",
    "    print(\"Checking if learning goals were achieved\")\n",
    "    check_learning_achieved(results, args.stop_reward)\n",
    "ray.shutdown()\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f440ff6-9d75-4466-8b96-19421a01be6f",
   "metadata": {},
   "source": [
    "1GPU V100  2CPU\n",
    "426 for 20000 with         num_gpus_per_learner_worker=1, num_learner_workers=1\n",
    "\n",
    "2CPU\n",
    "378.389 for 20000 without\n",
    "\n",
    "4GPU, 2CPU\n",
    "295.219 for 20000 with \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55edfb36-fe9d-47f1-a07d-cbaa2b709b29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
