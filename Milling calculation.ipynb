{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T15:51:21.729349Z",
     "start_time": "2024-03-07T15:51:21.253234Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "def generate_runner_dataframe(trainer):\n",
    "    assert trainer is not None\n",
    "\n",
    "    # Fetch episode states\n",
    "    episode_states = trainer.fetch_episode_states(\n",
    "        [\"loc_x\", \"loc_y\", \"still_in_the_game\"]\n",
    "    )\n",
    "    env = trainer.cuda_envs.env\n",
    "\n",
    "    episode_states[\"loc_x\"] = episode_states[\"loc_x\"]/ env.stage_size\n",
    "    episode_states[\"loc_y\"] = episode_states[\"loc_y\"]/ env.stage_size\n",
    "    assert isinstance(episode_states, dict)\n",
    "\n",
    "    # Create empty pandas dataframe\n",
    "    df = pd.DataFrame(columns=[\"time_step\", \"agent_id\", \"x\", \"y\", \"still_in_the_game\"])\n",
    "\n",
    "    # Loop over time steps and agents to initialize lines\n",
    "    for t in range(len(episode_states[\"loc_x\"])):\n",
    "        for i in range(len(episode_states[\"loc_x\"][0])):\n",
    "            if i not in env.predators:  # only include runners\n",
    "                df = df.append({\n",
    "                    \"time_step\": t,\n",
    "                    \"agent_id\": i,\n",
    "                    \"x\": episode_states[\"loc_x\"][t, i],\n",
    "                    \"y\": episode_states[\"loc_y\"][t, i],\n",
    "                    \"still_in_the_game\": episode_states[\"still_in_the_game\"][t, i]\n",
    "                }, ignore_index=True)\n",
    "\n",
    "    # Calculate velocity and orientation\n",
    "    df[\"delta_x\"] = df.groupby(\"agent_id\")[\"x\"].diff()\n",
    "    df[\"delta_y\"] = df.groupby(\"agent_id\")[\"y\"].diff()\n",
    "    df[\"velocity\"] = np.sqrt(df[\"delta_x\"] ** 2 + df[\"delta_y\"] ** 2)\n",
    "    df[\"orientation\"] = np.arctan2(df[\"delta_y\"], df[\"delta_x\"]) * 180 / np.pi\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_milling_parameters(df, threshold, min_group_size):\n",
    "    num_time_steps = df[\"time_step\"].nunique()\n",
    "    max_agents = df.groupby(\"time_step\").size().max()\n",
    "    pairwise_dists = np.zeros((num_time_steps, max_agents, max_agents))\n",
    "\n",
    "    for t in range(num_time_steps):\n",
    "        agents_t = df[df[\"time_step\"] == t][[\"x\", \"y\"]].values\n",
    "        n_agents_t = agents_t.shape[0]\n",
    "        pairwise_dists_t = np.zeros((max_agents, max_agents))\n",
    "        if n_agents_t > 1:\n",
    "            pairwise_dists_t[:n_agents_t, :n_agents_t] = distance_matrix(agents_t, agents_t)\n",
    "        pairwise_dists[t] = pairwise_dists_t\n",
    "        \n",
    "    groups = []\n",
    "    \n",
    "    for t in range(num_time_steps):\n",
    "        # Find pairs of agents that are close enough to be considered part of the same group\n",
    "        close_pairs = np.where(pairwise_dists[t] <= threshold)\n",
    "        close_pairs = np.sort(np.stack(close_pairs, axis=-1), axis=-1)\n",
    "        close_pairs = np.unique(close_pairs, axis=0)\n",
    "\n",
    "        # Build a graph of the close pairs of agents\n",
    "        graph = nx.Graph()\n",
    "        graph.add_edges_from(close_pairs)\n",
    "\n",
    "        # Identify connected components of the graph\n",
    "        connected_components = list(nx.connected_components(graph))\n",
    "\n",
    "        # Filter out groups that are smaller than the minimum size\n",
    "        groups_t = [list(component) for component in connected_components if len(component) >= min_group_size]\n",
    "        groups.append(groups_t)\n",
    "        \n",
    "        \n",
    "    for t in range(num_time_steps):\n",
    "        groups_t = groups[t]\n",
    "        num_groups_t = len(groups_t)\n",
    "\n",
    "        if num_groups_t == 0:\n",
    "            result.append({\n",
    "                \"time_step\": t,\n",
    "                \"num_groups\": 0,\n",
    "                \"mean_group_size\": 0,\n",
    "                \"std_group_size\": 0,\n",
    "                \"mean_group_speed\": 0,\n",
    "                \"std_group_speed\": 0,\n",
    "                \"mean_group_angular_velocity\": 0,\n",
    "                \"std_group_angular_velocity\": 0\n",
    "            })\n",
    "            continue\n",
    "        # Calculate orientation difference between consecutive rows\n",
    "        df[\"orientation_diff\"] = df[\"orientation\"].diff()\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        # Identify time steps where orientation difference exceeds threshold\n",
    "        df[\"orientation_change\"] = abs(df[\"orientation_diff\"]) > threshold\n",
    "        df[\"orientation_change\"] = df[\"orientation_change\"].astype(int)\n",
    "\n",
    "        # Identify groups of consecutive time steps where orientation change occurs\n",
    "        df[\"group\"] = df[\"orientation_change\"].diff()\n",
    "        df.loc[0, \"group\"] = 1\n",
    "        df[\"group_start\"] = df[\"group\"] == 1\n",
    "        df[\"group_end\"] = df[\"group\"] == -1\n",
    "        df.drop(\"group\", axis=1, inplace=True)\n",
    "        df[\"group\"] = df[\"group_start\"].cumsum()\n",
    "\n",
    "        # Identify groups that meet minimum size requirement\n",
    "        group_sizes = df.groupby(\"group\").size()\n",
    "        valid_groups = group_sizes[group_sizes >= min_group_size].index\n",
    "        df = df[df[\"group\"].isin(valid_groups)]\n",
    "\n",
    "        # Calculate mean and standard deviation of group angular velocity\n",
    "        group_orientations_t = [df.iloc[groups_t[i]][\"orientation\"].values for i in range(num_groups_t)]\n",
    "        group_orientations_t = np.stack(group_orientations_t)\n",
    "        group_ang_velocities_t = np.stack([np.mean(np.diff(group_orientations_t[i])) for i in range(num_groups_t)])\n",
    "        mean_group_ang_velocity_t = np.mean(group_ang_velocities_t)\n",
    "        std_group_ang_velocity_t = np.std(group_ang_velocities_t)\n",
    "\n",
    "        # Identify time steps where angular velocity exceeds threshold\n",
    "        df[\"ang_velocity\"] = df[\"orientation_diff\"].rolling(window=5).sum()\n",
    "        df[\"ang_velocity_change\"] = abs(df[\"ang_velocity\"]) > mean_group_ang_velocity_t + std_group_ang_velocity_t\n",
    "        df[\"ang_velocity_change\"] = df[\"ang_velocity_change\"].astype(int)\n",
    "\n",
    "        # Identify groups of consecutive time steps where angular velocity change occurs\n",
    "        df[\"group\"] = df[\"ang_velocity_change\"].diff()\n",
    "        df.loc[0, \"group\"] = 1\n",
    "        df[\"group_start\"] = df[\"group\"] == 1\n",
    "        df[\"group_end\"] = df[\"group\"] == -1\n",
    "        df.drop(\"group\", axis=1, inplace=True)\n",
    "        df[\"group\"] = df[\"group_start\"].cumsum()\n",
    "\n",
    "        # Identify groups that meet minimum size requirement\n",
    "        group_sizes = df.groupby(\"group\").size()\n",
    "        valid_groups = group_sizes[group_sizes >= min_group_size].index\n",
    "        df = df[df[\"group\"].isin(valid_groups)]\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "import numpy as np\n",
    "\n",
    "def calculate_group_properties(df, threshold, min_group_size):\n",
    "    num_time_steps = df[\"time_step\"].nunique()\n",
    "    max_agents = df.groupby(\"time_step\").size().max()\n",
    "    pairwise_dists = np.zeros((num_time_steps, max_agents, max_agents))\n",
    "    group_properties = pd.DataFrame(columns=[\"group_id\", \"group_size\", \"mean_group_speed\", \"mean_group_ang_velocity\", \"timestep\"])\n",
    "    \n",
    "    \n",
    "    for t in range(num_time_steps):\n",
    "        agents_t = df[df[\"time_step\"] == t][[\"x\", \"y\"]].values\n",
    "        n_agents_t = agents_t.shape[0]\n",
    "        pairwise_dists_t = np.zeros((max_agents, max_agents))\n",
    "        if n_agents_t > 1:\n",
    "            pairwise_dists_t[:n_agents_t, :n_agents_t] = distance_matrix(agents_t, agents_t)\n",
    "        pairwise_dists[t] = pairwise_dists_t\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Identify groups of agents that are milling together at each time step\n",
    "    groups = []\n",
    "    for t in range(num_time_steps):\n",
    "        # Find pairs of agents that are close enough to be considered part of the same group\n",
    "        close_pairs = np.where(pairwise_dists[t] <= threshold)\n",
    "        close_pairs = np.sort(np.stack(close_pairs, axis=-1), axis=-1)\n",
    "        close_pairs = np.unique(close_pairs, axis=0)\n",
    "\n",
    "        # Build a graph of the close pairs of agents\n",
    "        graph = nx.Graph()\n",
    "        graph.add_edges_from(close_pairs)\n",
    "\n",
    "        # Identify connected components of the graph\n",
    "        connected_components = list(nx.connected_components(graph))\n",
    "\n",
    "        # Filter out groups that are smaller than the minimum size\n",
    "        groups_t = [list(component) for component in connected_components if len(component) >= min_group_size]\n",
    "        groups.append(groups_t)\n",
    "\n",
    "    # Calculate milling parameters for each time step\n",
    "    result = []\n",
    "    for t in range(num_time_steps):\n",
    "        groups_t = groups[t]\n",
    "        num_groups_t = len(groups_t)\n",
    "\n",
    "        if num_groups_t == 0:\n",
    "            result.append({\n",
    "                \"time_step\": t,\n",
    "                \"num_groups\": 0,\n",
    "                \"mean_group_size\": 0,\n",
    "                \"std_group_size\": 0,\n",
    "                \"mean_group_speed\": 0,\n",
    "                \"std_group_speed\": 0,\n",
    "                \"mean_group_angular_velocity\": 0,\n",
    "                \"std_group_angular_velocity\": 0\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Calculate group properties\n",
    "        group_sizes_t = [len(group) for group in groups_t]\n",
    "        group_positions_t = [df.iloc[groups_t[i]][[\"x\", \"y\"]].values for i in range(num_groups_t)]\n",
    "\n",
    "        # Calculate mean and standard deviation of group size\n",
    "        mean_group_size_t = np.mean(group_sizes_t)\n",
    "        std_group_size_t = np.std(group_sizes_t)\n",
    "\n",
    "        # Calculate mean and standard deviation of group speed\n",
    "        group_velocities_t = np.stack([np.mean(np.diff(group_positions_t[i], axis=0), axis=0) for i in range(num_groups_t)])\n",
    "        group_speeds_t = np.sqrt(np.sum(group_velocities_t ** 2, axis=-1))\n",
    "        mean_group_speed_t = np.mean(group_speeds_t)\n",
    "        std_group_speed_t = np.std(group_speeds_t)\n",
    "\n",
    "        # Calculate mean and standard deviation of group angular velocity\n",
    "        group_orientations_t = [df.iloc[groups_t[i]][\"orientation\"].values for i in range(num_groups_t)]\n",
    "        max_len = max(len(a) for a in group_orientations_t)\n",
    "        group_orientations_t = [np.pad(a, (0, max_len - len(a)), mode='constant', constant_values=np.nan) for a in group_orientations_t]\n",
    "        group_orientations_t = np.stack(group_orientations_t)\n",
    "\n",
    "        group_ang_velocities_t = np.stack([np.mean(np.diff(group_orientations_t[i])) for i in range(num_groups_t)])\n",
    "        mean_group_ang_velocity_t = np.mean(group_ang_velocities_t)\n",
    "        std_group_ang_velocity_t = np.std(group_ang_velocities_t)\n",
    "\n",
    "        # Add group properties to dataframe\n",
    "        group_properties_t = pd.DataFrame({\n",
    "            \"group_id\": np.arange(num_groups_t),\n",
    "            \"group_size\": group_sizes_t,\n",
    "            \"mean_group_speed\": group_speeds_t,\n",
    "            \"mean_group_ang_velocity\": group_ang_velocities_t\n",
    "        })\n",
    "\n",
    "        # Add timestep to group properties\n",
    "        group_properties_t[\"timestep\"] = t\n",
    "\n",
    "        # Append group properties to master dataframe\n",
    "        group_properties = pd.concat([group_properties, group_properties_t], ignore_index=True)\n",
    "    \n",
    "    return group, group_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_runner_dataframe(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_milling = calculate_milling_parameters(df, threshold=0.1, min_group_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data = calculate_group_properties(df, threshold=0.1, min_group_size=4)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
